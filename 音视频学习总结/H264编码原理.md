### 视频为什么要进行编码压缩

一张720\*480的图像，用YUV420P的格式来表示，其大小为720\*480\*1.5约等于0.5MB。

​	如果是25帧，10分钟的数据量0.5M\*10\*60\*25=7500MB -> 7GB多

视频编码压缩的目的是降低视频数据大小，方便存储和传输

### 为什么压缩的原始数据采用YUV格式

​	1.视频编码是对一张张图像来进行的，彩色图像的格式是RGB，但RGB三个颜色是有相关性的

​	2.采样YUV格式，利用人对图像的感觉的生理特性，对于亮度信息比较敏感，而对于色度信息不太敏感，所以视频编码是将Y分量和UV分量分开来编码的，并且可以减少UV分量，比如之前的YUV420P

### 视频压缩原理

空间冗余

​	图像相邻像素之间有较强的相关性，比如一帧图像划分成多个16\*16的块之后，相邻的块很多时候都有比较明显的相似性。

时间冗余

​	视频序列的相邻前后帧图像之间内容相似，比如帧率为25fps的视频中前后两帧图像相差只有40ms，前后两张图像的变化较小，相似性很高。

​	比如，第一张完整的图像，第二张图像，只需记录相对于第一张有改动的地方

视觉冗余

​	利用人眼睛对某些细节不敏感，对图像中高频信息的敏感度小于低频信息的。可以去除图像中的一些高频信息，人眼看起来跟不去除高频信息差别不大(有损压缩)。

编码冗余（信息熵冗余）

​	一幅图像中不同像素出现的概率是不同的。对出现次数比较多的像素，用少的位数来编码。对出现次数比较少的像素，用多的位数来编码，能够减少编码的大小。比如哈夫曼编码。

​	出现概率越大的，使用更少的bit去表示，编码压缩，数值越小，那需要的字节越少。

### 图像帧的类型（I、P、B帧）

I帧（关键帧或帧内帧），仅由帧内预测的宏块组成

P帧代表预测帧，除帧内空域预测以外，它还可以通过时域预测来进行压缩。P帧通过使用已经编码的帧进行运动估计

B帧可以参考在其前后出现的帧，B帧中的B代表双向（Bi-Directional）

B帧带来编码延时  后面补上这个笔记

### GOP(一组图像，Group of Pictures)和GOP长度

​	一个序列的第一个图像叫做IDR图像（立即刷新图像），IDR图像都是I帧图像。

在视频编码序列中，GOP即Group of picture(图像组)，指两个IDR帧之间的距离。

![image-20220321230636510](\\192.168.1.114\samba\github\AVideoLearning\音视频学习总结\截图\image-20220321230636510.png)

​	GOP长度越大，视频压缩效率越高，但视频质量和视频流恢复能力也越差，反正亦然。

![image-20220322004359980](\\192.168.1.114\samba\github\AVideoLearning\音视频学习总结\截图\image-20220322004359980.png)

留下问题？I帧和IDR帧的区别？图像压缩和矩阵压缩的关系？

gop设置5秒可以吗？看场景。gop length = 25\*5=125帧

​	直播领域，就不行，假如一个客户端连进来，刚好获取到I帧，马上显示画面，如果恰好错过I帧，要等5秒才能显示画面。

​	直播，如果是一秒25帧，一般gop设置为 25， 50（一般是帧率的倍数）

​	如果不是直播流，B帧一般设置2帧连续B帧，以降低码率。B帧省内存。

### H264编码原理

​	对于每一帧图像，是划分为一个个块进行编码，就是我们说的宏块。

​	宏块大小一般是16x16（H264、VP8）,32x32(H265,VP9)，64x64(H265、VP9、AV1),128x128(AV1)

​	预测    利用相邻像素的相关性，相邻像素一般变化不会特别大

​	水平预测， 垂直预测

​	帧间预测

​	DCT变换

​	直播的时候，带宽好，码率设置高一些。网络差，码率设置低一些。

​	能不能动态修改码率？  是可以的。 

​	qp值，

​			pps有字段： pic_init_qp_minus

​	slice:

​			slice_qp_delta

### FFmpeg H264编码

​	从本地读取yuv文件数据编码h264格式的数据，然后存入到本地，编码后数据有带startcode。

#### 	编码流程